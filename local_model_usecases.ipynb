{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da4b71c",
   "metadata": {},
   "source": [
    "### Succesfully used GPT4ALL to deploy a LLM locally, collaborating with LangChain\n",
    "Followed this tutorial: https://betterprogramming.pub/private-llms-on-local-and-in-the-cloud-with-langchain-gpt4all-and-cerebrium-6dade79f45f6\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01c4a59b",
   "metadata": {},
   "source": [
    "### The exact example given from that blog:\n",
    "\n",
    "```python\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "import os\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "model_path=\"/Users/hann/Projects/RES_LLM/private-llm/models/\"\n",
    "#  models are ggml-mpt-7b-chat.bin, ggml-gpt4all-l13b-snoozy.bin, ggml-gpt4all-j-v1.3-groovy.bin, ggml-mpt-7b-instruct.bin, ggml-v3-13b-hermes-q5_1.bin\n",
    "\n",
    "models={\n",
    "    \"groovy\": os.path.join(model_path, \"ggml-gpt4all-j-v1.3-groovy.bin\"),\n",
    "    \"snoozy\": os.path.join(model_path, \"ggml-gpt4all-l13b-snoozy.bin\"),\n",
    "    \"7bchat\": os.path.join(model_path, \"ggml-mpt-7b-chat.bin\"),\n",
    "    \"7binstruct\": os.path.join(model_path, \"ggml-mpt-7b-instruct.bin\"),\n",
    "    \"hermes\": os.path.join(model_path, \"ggml-v3-13b-hermes-q5_1.bin\")\n",
    "}\n",
    "\n",
    "template = \"\"\"\n",
    "You are a friendly chatbot assistant that responds in a conversational\n",
    "manner to users questions. Keep the answers short, unless specifically\n",
    "asked by the user to elaborate on something.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm = GPT4All(\n",
    "    model=models[\"groovy\"],\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"Where is Paris?\"\n",
    "llm_chain(question)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Found model file at  /Users/hann/Projects/RES_LLM/private-llm/models/ggml-mpt-7b-instruct.bin\n",
    "mpt_model_load: loading model from '/Users/hann/Projects/RES_LLM/private-llm/models/ggml-mpt-7b-instruct.bin' - please wait ...\n",
    "mpt_model_load: n_vocab        = 50432\n",
    "mpt_model_load: n_ctx          = 2048\n",
    "mpt_model_load: n_embd         = 4096\n",
    "mpt_model_load: n_head         = 32\n",
    "mpt_model_load: n_layer        = 32\n",
    "mpt_model_load: alibi_bias_max = 8.000000\n",
    "mpt_model_load: clip_qkv       = 0.000000\n",
    "mpt_model_load: ftype          = 2\n",
    "mpt_model_load: ggml ctx size = 5653.09 MB\n",
    "mpt_model_load: kv self size  = 1024.00 MB\n",
    "mpt_model_load: ........................ done\n",
    "mpt_model_load: model size =  4629.02 MB / num tensors = 194\n",
    "========================================\n",
    "========================================\n",
    "Model: 7binstruct\n",
    "It seems like Charles Darwin, while exploring South America as part of his work with the British Navy started to notice how animals and plants differed between islands.  He noticed this was related back in England after he published The Origin Of Species by means of Natural Selection, a book where is described that evolution occurs because some traits are better suited for specific environments than others, which were easier selected over time as they provided more benefits or advantages to the animal who had those particular features.\n",
    "\n",
    "It seems like Charles Darwin, while exploring South America as part of his work with the British Navy started to notice how animals and plants differed between islands.  He noticed this was related back in England after he published The Origin Of Species by means of Natural Selection, a book where is described that evolution occurs because some traits are better suited for specific environments than others, which were easier selected over time as they provided more benefits or advantages to the animal who had those particular features.\n",
    "\n",
    "**The 7binstruct model elapsed 48.45 seconds**\n",
    "========================================\n",
    "========================================\n",
    "Found model file at  /Users/hann/Projects/RES_LLM/private-llm/models/ggml-gpt4all-j-v1.3-groovy.bin\n",
    "gptj_model_load: loading model from '/Users/hann/Projects/RES_LLM/private-llm/models/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
    "gptj_model_load: n_vocab = 50400\n",
    "gptj_model_load: n_ctx   = 2048\n",
    "gptj_model_load: n_embd  = 4096\n",
    "gptj_model_load: n_head  = 16\n",
    "gptj_model_load: n_layer = 28\n",
    "gptj_model_load: n_rot   = 64\n",
    "gptj_model_load: f16     = 2\n",
    "gptj_model_load: ggml ctx size = 5401.45 MB\n",
    "gptj_model_load: kv self size  =  896.00 MB\n",
    "gptj_model_load: ................................... done\n",
    "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n",
    " It's located at latitude 48 degrees north and longitude 2 west of Greenwich Mean Time (GMT).\n",
    " It's located at latitude 48 degrees north and longitude 2 west of Greenwich Mean Time (GMT).\n",
    "{'question': 'Where is Paris?',\n",
    " 'text': \" It's located at latitude 48 degrees north and longitude 2 west of Greenwich Mean Time (GMT).\"}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ecc9a",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46fb56f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  /Users/hann/Projects/RES_LLM/private-llm/models/ggml-mpt-7b-instruct.bin\n",
      "mpt_model_load: loading model from '/Users/hann/Projects/RES_LLM/private-llm/models/ggml-mpt-7b-instruct.bin' - please wait ...\n",
      "mpt_model_load: n_vocab        = 50432\n",
      "mpt_model_load: n_ctx          = 2048\n",
      "mpt_model_load: n_embd         = 4096\n",
      "mpt_model_load: n_head         = 32\n",
      "mpt_model_load: n_layer        = 32\n",
      "mpt_model_load: alibi_bias_max = 8.000000\n",
      "mpt_model_load: clip_qkv       = 0.000000\n",
      "mpt_model_load: ftype          = 2\n",
      "mpt_model_load: ggml ctx size = 5653.09 MB\n",
      "mpt_model_load: kv self size  = 1024.00 MB\n",
      "mpt_model_load: ........................ done\n",
      "mpt_model_load: model size =  4629.02 MB / num tensors = 194\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate\n",
    "import os\n",
    "import timeit\n",
    "model_path=\"/Users/hann/Projects/RES_LLM/private-llm/models/\"\n",
    "\n",
    "#  models are ggml-mpt-7b-chat.bin, ggml-gpt4all-l13b-snoozy.bin, ggml-gpt4all-j-v1.3-groovy.bin, ggml-mpt-7b-instruct.bin, ggml-v3-13b-hermes-q5_1.bin\n",
    "\n",
    "models={\n",
    "    \"groovy\": os.path.join(model_path, \"ggml-gpt4all-j-v1.3-groovy.bin\"),\n",
    "    \"snoozy\": os.path.join(model_path, \"ggml-gpt4all-l13b-snoozy.bin\"),\n",
    "    \"7bchat\": os.path.join(model_path, \"ggml-mpt-7b-chat.bin\"),\n",
    "    \"7binstruct\": os.path.join(model_path, \"ggml-mpt-7b-instruct.bin\"),\n",
    "    \"hermes\": os.path.join(model_path, \"ggml-v3-13b-hermes-q5_1.bin\")\n",
    "}\n",
    "\n",
    "#  \"groovy\", \"snoozy\",  \"7bchat\", \"7binstruct\", \"hermes\"\n",
    "md = \"7binstruct\"\n",
    "\n",
    "llm = GPT4All(model=models[md], callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1844f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "========================================\n",
      "Model: 7binstruct\n",
      "It seems like Charles Darwin, while exploring South America as part of his work with the British Navy started to notice how animals and plants differed between islands.  He noticed this was related back in England after he published The Origin Of Species by means of Natural Selection, a book where is described that evolution occurs because some traits are better suited for specific environments than others, which were easier selected over time as they provided more benefits or advantages to the animal who had those particular features.\n",
      "\n",
      "It seems like Charles Darwin, while exploring South America as part of his work with the British Navy started to notice how animals and plants differed between islands.  He noticed this was related back in England after he published The Origin Of Species by means of Natural Selection, a book where is described that evolution occurs because some traits are better suited for specific environments than others, which were easier selected over time as they provided more benefits or advantages to the animal who had those particular features.\n",
      "\n",
      "**The 7binstruct model elapsed 48.45 seconds**\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the template\n",
    "template = \"\"\"\n",
    "%INSTRUCTIONS:\n",
    "You are a friendly chatbot assistant that summarises user's texts. Now, please summarize the following piece of text.\n",
    "\n",
    "%TEXT:\n",
    "{text}\n",
    "\n",
    "%SUMMARY:\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplte object for later use, utilizing the defined template and var text\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "\n",
    "confusing_text = \"\"\"\n",
    "Shortly after graduating from Cambridge, he got a job as a naturalist on the ship H.M.S. Beagle, which was about to start on a scientific and cartographic survey of the South American coast. The journey started in December 1831 and was to last almost five years, during which time he amassed considerable documentation.\n",
    "Darwin was particularly struck by the fauna of the south seas, notably by the tortoises he found on the Galapagos Islands, a group of Pacific Islands where nature seemed different from nature in other lands. The Galapagos tortoises, Darwin observed, differed from island to island, and this, he deduced, implied different forms of evolution, since the animals obviously came from the same origins. Darwin was also struck by the iguanas he found, and observed that those which lived in water had heads suitable for finding food among stones, whilst those that lived on land had a sharper profile, more fit for a herbivorous animal.\n",
    "\"\"\"\n",
    "\n",
    "# final_prompt=prompt.format(text=confusing_text)\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# llm_chain(confusing_text)\n",
    "\n",
    "# Decorator: Neat output, including seperating line and timer\n",
    "def neat(func):\n",
    "    def wrapper():\n",
    "        print(\"========================================\")\n",
    "        print(f\"Model: {md}\")\n",
    "\n",
    "        # func()\n",
    "\n",
    "        print(f\"\\n**The {md} model elapsed {timeit.timeit(func, number=1):.2f} seconds**\")\n",
    "        print(\"========================================\")\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@neat\n",
    "def run_model():\n",
    "\n",
    "    # final_prompt=prompt.format(text=confusing_text)\n",
    "    # print(\"========================================\")\n",
    "    llm(prompt.format(text=confusing_text))\n",
    "\n",
    "\n",
    "\n",
    "run_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
